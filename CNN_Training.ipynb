{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "zBdSpCUwsnXr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X1 = torch.tensor([[40.2]], dtype=torch.float32)\n",
        "y1 = torch.tensor([[20.1]], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "HHbljiVesx0X"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(1,1)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOpSWx1zsx5W",
        "outputId": "778045b8-2980-4947-edc5-558f0dacbcf3"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1, out_features=1, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.MSELoss()"
      ],
      "metadata": {
        "id": "FGTTjWD4sx8P"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYx_B3WNsx_I",
        "outputId": "e58ba728-0a6c-4179-b666-5bf9af894bdf"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.001\n",
              "    maximize: False\n",
              "    momentum: 0\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in model.parameters():\n",
        "  print(i)  #1st one is weight, 2nd is bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgV_u_m1syCL",
        "outputId": "af8c99d2-30a8-4ae7-f63b-b925b5a397ad"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[0.3963]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.2359], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Before training\n",
        "model.weight, model.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0JufNHTsyFY",
        "outputId": "0e873808-639c-4025-887e-69c9052893ae"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[0.3963]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.2359], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check gradients before zeroing\n",
        "print(\"Gradients before zeroing:\")\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0XrvxLqvr47",
        "outputId": "a4f7f73e-c6e5-4fd3-9b54-2eb1136cf637"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients before zeroing:\n",
            "weight: None\n",
            "bias: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Start Training\n",
        "optimizer.zero_grad()  #To reset the gradients of all the parameters in an optimizer to zero."
      ],
      "metadata": {
        "id": "xDNVYbGRsyMj"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nGradients after zeroing:\")\n",
        "for name, param in model.named_parameters():\n",
        "    if param.grad is not None:\n",
        "        print(f\"{name}: {param.grad.norm().item()}\")\n",
        "    else:\n",
        "        print(f\"{name}: None (gradients cleared)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lSyDhQ5syYa",
        "outputId": "14d9d5a2-e144-4381-b88d-6084aada6d93"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gradients after zeroing:\n",
            "weight: None (gradients cleared)\n",
            "bias: None (gradients cleared)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(X1)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0KSDUPzvPxi",
        "outputId": "9a993249-84c4-4338-b6f8-306f7a4297a3"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[16.1684]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = loss_fn(outputs, y1)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7dzK1SovP0t",
        "outputId": "99058f4c-412d-4c83-9c96-4dd78ec3bc96"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(15.4578, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##What loss.backward() Does\n",
        "\n",
        "####**Computes Gradients:** It calculates the partial derivatives of the loss function with respect to each parameter in the model (e.g., weights and biases) that has requires_grad=True. These gradients are stored in the **.grad attribute** of each parameter.\n",
        "####**Backpropagation:** It performs backpropagation, propagating the loss gradient backward through the computational graph (from the loss to the inputs) using the **chain rule.**\n",
        "####**Accumulates Gradients:** Gradients are accumulated into the .grad attribute of each parameter. If .grad already contains values (from a previous backward() call), new gradients are added unless cleared with optimizer.zero_grad()."
      ],
      "metadata": {
        "id": "G0ke2K4DxUja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s1ZQxFUvP8b",
        "outputId": "d3e195fa-d24e-4106-dc64-50d6d9315df1"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(15.4578, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**optimizer.step()** is a key method in PyTorch optimizers (like optim.SGD or optim.Adam) that updates the model's parameters based on the gradients computed during the backward pass. It applies the optimization algorithm to adjust the weights and biases, effectively taking a \"step\" towards minimizing the loss."
      ],
      "metadata": {
        "id": "9fZ2Zeqey4ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.step()\n",
        "optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqUS_2aTvQBe",
        "outputId": "4c7550ae-3988-492d-f90c-d151df23b290"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.001\n",
              "    maximize: False\n",
              "    momentum: 0\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#After training\n",
        "model.weight,model.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbvnRy0Vy_BD",
        "outputId": "0f38d067-9952-4577-cd97-68bfd2e6b892"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[0.7124]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.2438], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1_pred = model(X1)\n",
        "y1_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrceuNeNzR-X",
        "outputId": "e9d7a962-8308-41e7-ed03-4bee1669c451"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[28.8836]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    }
  ]
}